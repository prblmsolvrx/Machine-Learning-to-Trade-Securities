# Importing required libraries
from datasets import load_dataset  # Importing a function to load datasets from the Hugging Face dataset library
import pandas as pd  # Importing pandas for data manipulation and analysis
from sklearn.preprocessing import StandardScaler  # Importing StandardScaler for feature scaling
from sklearn.model_selection import cross_val_score  # Importing cross_val_score for cross-validation
from sklearn.ensemble import GradientBoostingRegressor  # Importing GradientBoostingRegressor for regression modeling
import matplotlib.pyplot as plt  # Importing matplotlib for data visualization

# Load the Tesla dataset
tesla = load_dataset('codesignal/tsla-historic-prices')  # Loading Tesla historic prices dataset
tesla_df = pd.DataFrame(tesla['train'])  # Converting the loaded dataset into a pandas DataFrame

# Convert the 'Date' column to datetime type for easier manipulation
tesla_df['Date'] = pd.to_datetime(tesla_df['Date'])

# Feature Engineering: Creating a new column 'Target' representing the difference between the next day's adjusted close and current adjusted close
tesla_df['Target'] = tesla_df['Adj Close'].shift(-1) - tesla_df['Adj Close']

# Calculate Simple Moving Average (SMA) over a 5-day window and add it as a new column 'SMA_5'
tesla_df['SMA_5'] = tesla_df['Adj Close'].rolling(window=5).mean()

# Calculate Simple Moving Average (SMA) over a 10-day window and add it as a new column 'SMA_10'
tesla_df['SMA_10'] = tesla_df['Adj Close'].rolling(window=10).mean()

# Calculate Exponential Moving Average (EMA) over a 5-day span and add it as a new column 'EMA_5'
tesla_df['EMA_5'] = tesla_df['Adj Close'].ewm(span=5, adjust=False).mean()

# Calculate Exponential Moving Average (EMA) over a 10-day span and add it as a new column 'EMA_10'
tesla_df['EMA_10'] = tesla_df['Adj Close'].ewm(span=10, adjust=False).mean()

# Drop rows with NaN values generated by moving averages calculations
tesla_df.dropna(inplace=True)

# Selecting features (independent variables) and target (dependent variable)
features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5', 'SMA_10', 'EMA_5', 'EMA_10']].values  # Extracting feature columns as a NumPy array
target = tesla_df['Target'].values  # Extracting the target variable as a NumPy array

# Standardizing features to have zero mean and unit variance
scaler = StandardScaler()  # Creating an instance of StandardScaler
features_scaled = scaler.fit_transform(features)  # Fitting the scaler to features and transforming them

# Instantiate the Gradient Boosting Regressor model with specified parameters
model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Perform 5-fold cross-validation on the model using scaled features and target
scores = cross_val_score(model, features_scaled, target, cv=5)  # Obtaining cross-validation scores
mean_score = scores.mean()  # Calculating the mean of cross-validation scores
print("Mean cross-validation score: ", mean_score)  # Printing the mean cross-validation score

# Fit the model to the entire dataset to visualize predictions
model.fit(features_scaled, target)  # Training the model on the full dataset
predictions = model.predict(features_scaled)  # Making predictions on the scaled features

# Plotting the predicted values against the actual values
plt.figure(figsize=(10, 6))  # Creating a figure with a specified size
plt.plot(range(len(target)), target, label='Actual', alpha=0.7, color='blue')  # Plotting the actual values
plt.plot(range(len(target)), predictions, label='Predicted', alpha=0.7, color='orange')  # Plotting the predicted values
plt.title('Actual vs Predicted Values with Cross-Validation')  # Setting the title of the plot
plt.xlabel('Sample Index')  # Labeling the x-axis
plt.ylabel('Value')  # Labeling the y-axis
plt.legend()  # Displaying the legend to differentiate between actual and predicted values
plt.show()  # Displaying the plot

"""
Mean cross-validation score:  -0.21139860331328936
"""