# Import necessary libraries
from datasets import load_dataset  # Function to load datasets from the 'datasets' library
import pandas as pd  # Import pandas for data manipulation
from sklearn.preprocessing import StandardScaler  # For standardizing features
from sklearn.model_selection import cross_val_score  # For performing cross-validation
from sklearn.ensemble import GradientBoostingRegressor  # Gradient Boosting model for regression tasks
import matplotlib.pyplot as plt  # For plotting data

# Load dataset
tesla = load_dataset('codesignal/tsla-historic-prices')  # Load the Tesla historic prices dataset from CodeSignal
tesla_df = pd.DataFrame(tesla['train'])  # Convert the dataset to a DataFrame

# Convert Date column to datetime type
tesla_df['Date'] = pd.to_datetime(tesla_df['Date'])  # Convert the 'Date' column to datetime for easier manipulation

# Feature Engineering
tesla_df['Target'] = tesla_df['Adj Close'].shift(-1) - tesla_df['Adj Close']  # Create target variable as the next day's price change
tesla_df['SMA_5'] = tesla_df['Adj Close'].rolling(window=5).mean()  # Calculate the 5-day Simple Moving Average
tesla_df['SMA_10'] = tesla_df['Adj Close'].rolling(window=10).mean()  # Calculate the 10-day Simple Moving Average
tesla_df['EMA_5'] = tesla_df['Adj Close'].ewm(span=5, adjust=False).mean()  # Calculate the 5-day Exponential Moving Average
tesla_df['EMA_10'] = tesla_df['Adj Close'].ewm(span=10, adjust=False).mean()  # Calculate the 10-day Exponential Moving Average

# Drop NaN values created by moving averages
tesla_df.dropna(inplace=True)  # Remove rows with NaN values generated by moving average calculations

# Select features and target
features = tesla_df[['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5', 'SMA_10', 'EMA_5', 'EMA_10']].values  # Select feature columns as a NumPy array
target = tesla_df['Target'].values  # Extract target values as a NumPy array

# Standardizing features
scaler = StandardScaler()  # Instantiate a StandardScaler object for feature scaling
features_scaled = scaler.fit_transform(features)  # Scale the features to have zero mean and unit variance

# Instantiate model
model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)  # Initialize the Gradient Boosting Regressor with specified parameters

# Perform cross-validation with 5 folds and print the mean score
scores = cross_val_score(model, features_scaled, target, cv=5)  # Perform 5-fold cross-validation
mean_score = scores.mean()  # Calculate the mean cross-validation score
print("Mean cross-validation score: ", mean_score)  # Print the mean cross-validation score

# Fit model to visualize predictions
model.fit(features_scaled, target)  # Fit the model to the entire dataset to visualize predictions
predictions = model.predict(features_scaled)  # Predict target values using the fitted model

# Plotting predictions vs actual values
plt.figure(figsize=(10, 6))  # Create a figure for plotting with specified dimensions
plt.scatter(range(len(target)), target, label='Actual', alpha=0.7)  # Scatter plot for actual target values
plt.scatter(range(len(target)), predictions, label='Predicted', alpha=0.7)  # Scatter plot for predicted values
plt.title('Actual vs Predicted Values with Cross-Validation')  # Set the title of the plot
plt.xlabel('Sample Index')  # Set the x-axis label
plt.ylabel('Value')  # Set the y-axis label
plt.legend()  # Display the legend to differentiate actual vs predicted
plt.show()  # Display the plot

"""
Mean cross-validation score:  -0.21139860331328936
"""
